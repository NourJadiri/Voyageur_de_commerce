# Le problème du voyageur de commerce

## Installation des packets
On commence par installer les packets nécessaires au bon fonctionnement du code.
```{r}
install.packages(c("maps","sp","Rcpp","TSP","microbenchmark","multcomp"), repos = "http://cran.rstudio.com")
install.packages("packages/TSPpackage_2.0.zip", repos = NULL, type = "bin")
```
On charge ensuite les packets dans le projets.
```{r}
for (pkg in c("maps","sp","Rcpp","TSP","microbenchmark","multcomp", "TSPpackage")) {
  library(pkg, character.only = TRUE)
}

```

## Setup initial

On fixe la seed pour avoir des résultats reproductibles.
```{r}
set.seed(287)
```

# 0. Visualisation de chemins

Lecture du fichier des villes :

```{r}
villes <- read.csv('data/DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
```
Représentation des chemins par plus proches voisins et du chemin optimal :
```{r}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins est de `4303.568`
```{r, echo=FALSE}
voisins$longueur
```
et pour la méthode optimale est de `3793.06`
```{r, echo=FALSE}
calculeLongueur(dist,pathOpt)
```

Ceci illustre bien l'intérêt d'un algorithme de calcul de chamin optimal pour un voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.


# 1. Comparaison d'algorithmes

On commence par créer un graphe de 10 nœuds, auquels on associe des coordonnées qui suivent une loi uniforme $U[0,1]$.
```{r, echo=TRUE}
n <- 10 #nombre de noeud

#example de lancement unitaire
sommets <- data.frame(x = runif(n), y = runif(n))
```

Ensuite, on calcule la matrice des distances entre les noeuds grâce à la fonction distance.
```{r}
couts <- distance(sommets)
```

On effectue un premier test pour calculer un chemin pour le voyageur de commerce. La méthode retenue ici est la méthode nearest, qui consiste à choisir le noeud le plus proche du noeud courant.
```{r, echo=TRUE}
TSPsolve(couts,'nearest')
```

Par la suite, nous allons comparer les performances de 5 méthodes de résolution du problème du voyageur de commerce. Ces méthodes sont les suivantes :

   * arbitrary_insertion : insertion arbitraire

   * repetitive_nn : plus proche voisin répétitif

   * two_opt : 2-opt

   * nearest : plus proche voisin

   * branch : branch and bound

On crée 50 graphes de 10 noeuds, auquels on associe des coordonnées qui suivent une loi uniforme $U[0,1]$.
On calcule ensuite la longueur des chemins obtenus par les 5 méthodes de résolution du problème du voyageur de commerce.
Les résultats sont alors stockés dans un tableau, triés par méthode.
```{r, echo=TRUE}

#calcul de plusieurs simulation de graphes qui seront analysées par les 5 méthodes
nsimu <- 50 #nombre de simulations
methods <- c('arbitrary_insertion', 'repetitive_nn','two_opt','nearest','branch')
res <- array(0,dim=c(nsimu,length(methods)))
for(i in 1:nsimu){
  points <- data.frame(x = runif(n), y = runif(n))
  dist <- distance(points)
  res[i,] <- (sapply(methods, function(m){TSPsolve(dist,m)}))
}
colnames(res) <- c('insertion','repet_nn','two_opt','nearest','branch')

```

## 1.1. Longueur des chemins

Chacune des méthodes de résolution du problème du voyageur de commerce renvoie un chemin, dont on a calculé la longueur précédemment.
```{r, echo=TRUE}
res2 <- as.vector(res)
meth_names <- c('insertion','repetitive_nn','two_opt','nearest','branch')
methods2 <- rep(meth_names,each=nsimu)

# get the mean of each method
boxplot(res2~methods2)
```

Nous remarquons que la méthode 'branch' est la plus efficace en terme de longueur de chemin. En effet, sa médiane est la plus faible et son interquartile est le plus petit. De plus, son quartile supérieur est très petit, donc plus de valeurs supérieures à la médiane sont proches de celle-ci.

Ensuite la méthode insertion est la seconde plus efficace, très similaire à la méthode 'branch' avec un quartile supérieur un peu plus grand, et une valeur minimale plus basse que branch.
La méthode 'nearest' est la moins efficace, avec une médiane très élevée et un quartile supérieur très grand. Nous observons également des valeurs extrêmes dispersées.

### Test entre 'nearest' et 'branch'

Soient $m_nn$ et $m_b$ les espérences respectives des longueurs des chemins obtenus par les méthodes 'nearest' et 'branch'.

On teste l'hypothèse $(H_0) : m_nn - m_b <= 0 $ contre l'hypothèse $(H_1) : m_nn - m_b > 0$


```{r, echo=TRUE}
t.test(res[,4],res[,5],alternative='greater')
```
Après la réalisation du test de Welch pour comparer les moyennes des méthodes 'nearest' et 'branch', nous remarquons que la longueur moyenne calculée par la méthode 'nearest' est statistiquement significativement supérieure à celle de la méthode 'branch' 4.59 vs 3.78.

La statistique de test (t) est de 4.0247, indiquant à quel point la différence observée entre les moyennes est éloignée de zéro, ajustée en fonction de la taille des échantillons et de leur variance.

La p-value est très faible (4.958e-12), indiquant une forte preuve contre l'hypothèse nulle. Nous pouvons donc rejeter l'hypothèse nulle et conclure que la longueur moyenne de la méthode 'nearest' est statistiquement significativement supérieure à celle de la méthode 'branch'.

L'intervalle de confiance pour la différence des moyennes va de 0.6385702 à l'infini (Inf), indiquant qu'à partir de cet intervalle, il y a 95% de chances que la $m_nn > m_b$.

Cela montre que en effet la méthode 'branch' est la plus efficace en termes de longueur de chemin que la méthode 'nearest'.

### Tests 2 à 2

On teste l'hypothèse $(H_0) : m_i - m_j = 0$ contre l'hypothèse $(H_1) : m_i - m_j \neq 0$ pour $i \neq j$ et $i,j \in \{1,2,3,4,5\}$

```{r, echo=TRUE}
pairwise.t.test(res2, methods2, p.adjust.method = 'bonferroni')
```
Dans la sortie de ce test pairwise, des comparaisons ont été effectuées entre différentes méthodes (branch, insertion, nearest, repetitive_nn, two_opt) à l'aide de tests t avec des écarts-types groupés, et les p-values résultantes ont été ajustées en utilisant la méthode de Bonferroni.

Examinons quelques valeurs spécifiques pour illustrer l'interprétation :

La p-value pour la comparaison entre "nearest" et "branch" est de 0.00062. Cette p-value est inférieure au seuil de signification ajusté par la correction de Bonferroni. Par conséquent, on peut conclure qu'il existe une différence statistiquement significative entre les méthodes "nearest" et "branch".

En revanche, pour la comparaison entre "insertion" et "branch", la p-value est de 1.00000, ce qui est bien au-dessus du seuil ajusté. On ne peut pas rejeter l'hypothèse nulle dans ce cas, suggérant qu'il n'y a pas de différence statistiquement significative entre "insertion" et "branch".

La comparaison entre "repetitive_nn" et "nearest" a une p-value de 0.02144, ce qui est inférieur au seuil ajusté. On peut conclure qu'il existe une différence statistiquement significative entre ces deux méthodes.

Pour "two_opt" vs "repetitive_nn", la p-value est de 0.23944, ce qui est au-dessus du seuil ajusté. On ne rejette pas l'hypothèse nulle dans ce cas, suggérant qu'il n'y a pas de différence statistiquement significative entre ces deux méthodes.

En résumé, l'ajustement de Bonferroni a été appliqué pour contrôler le taux global d'erreur de type I lors de multiples comparaisons. Les valeurs p inférieures au seuil ajusté suggèrent des différences statistiquement significatives entre les méthodes correspondantes, tandis que les valeurs p plus élevées suggèrent l'absence de différences significatives


## 1.2. Temps de calcul

Comparaison des temps à l'aide du package microbenchmark.

Exemple d'application de microbenchmark :
```{r, echo=TRUE}
microbenchmark(sqrt(x),x^0.5, times=100, setup={x <- runif(1)})
```
Exemple d'application de la fonction TSPsolve :
# Application du microbenchMark sur les 5 méthodes

```{r, echo=TRUE}
n <- 10 #nombre de noeud

microbenchmark(TSPsolve(dist,method='arbitrary_insertion'),TSPsolve(dist,method='repetitive_nn'),TSPsolve(dist,method='two_opt'),TSPsolve(dist,method = 'nearest'),TSPsolve(dist, method = 'branch'),times=20,setup={points <- data.frame(x = runif(n), y = runif(n)) ; dist <- distance(points)})

#boxplot(moyennes)
```


# 2. Etude e la complexité de l'algorithme Branch and Bound

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

Nous construisons un modèle de régression linéaire du temps d'execution de Branch & Bound en fonction du nombre de sommet n.

```{r}
seqn <- seq(4,20,1)
temps <- array(0,dim=c(length(seqn),10))
  for(i in seq_along(seqn))
  {
    temps[i,]<-microbenchmark(TSPsolve(couts, method = 'branch'), times = 10,
                                                 setup = { n <- seqn[i]; couts <- distance(cbind(x = runif(n), y = runif(n))) })$time
  }
temps
```
# representer la variance des temps d'exécution en fonction de n
```{r}
par(mfrow=c(1,2)) # 2 graphiques sur 1 ligne
matplot(seqn, temps, xlab='n', ylab='temps')
matplot(seqn, log(temps)^2, xlab='n', ylab=expression(log(temps)^2))


```

```{r,echo=TRUE}
vect_temps<- log(as.vector(temps))^2
vect_dim <- rep(seqn,10)
temps.lm <- lm(vect_temps~vect_dim)
summary(temps.lm)
```

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(temps.lm)
plot(temps.lm,which=4) #pour avoir les disctances de cooks
```


Ajustement du modèle linéaire de $\log(temps)^2$ en fonction de $n$.

Analyse de la validité du modèle :

  * pertinence des coefficients et du modèle,

  * étude des hypothèses sur les résidus.
```{r,Echo=TRUE}
shapiro.test(residuals(temps.lm))
```
## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen

Récupération du temps moyen.

```{r,echo=TRUE}
temps.moy <- rowMeans(temps)
temps.moy
```
Réaliser l’ajustement du modèle de régression linéaire simple gaussien de log(temps.moy)ˆ2 en fonction de
seqn. Récupérer les principales statistiques. Faire l’étude des résidus. Conclure quant à la validité du modèle.

```{r,echo=TRUE}
temps.moy.lm <- lm(log(temps.moy)^2~seqn)
summary(temps.moy.lm)
```
Coefficients :
Les coefficients du modèle sont les suivants :

Intercept : 82.2045
Vect_dim (seqn) : 14.7581
Les coefficients estimés indiquent l'effet sur le carré du logarithme des temps moyens pour une unité d'augmentation de la séquence.

Statistiques de Test :
On observe des valeurs de p très faibles (<2e-16) sur les statistiques de test, indiquant une forte validité. 

Les résidus semblent être centrés autour de zéro et sont répartis de manière relativement homogène, suggérant une bonne adéquation du modèle.

Résidual Standard Error :
L'erreur standard des résidus est de 28.06, elle resprésente une mesure la dispersion des résidus.

R-squared : 0.8705
R-squared ajusté : 0.8697
Ce coefficient élevé de détermination suggère une bonne adéquation du modèle aux données.

Test de Normalité Shapiro-Wilk :
Egalement les hypothèses sur les résidus sont vérifiées car le test de shapiro est supérieur à 0.05.

Conclusion :
En conclusion, le modèle de régression linéaire simple semble être statistiquement significatif et présente une adéquation acceptable avec les données. 

## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.
```{r,echo=TRUE}
donnees <- read.csv(file='data/DonneesTSP.csv',header=TRUE)
data.graph <- as.data.frame(donnees)
```

On construit ensuite le modèle de régression linéaire de $log(tps)$ par rapport à $\sqrt{dim}$ et toutes les autres variables de data.graph.
```{r,echo=TRUE}
data.graph$log.tps <- log(donnees$tps)#log(donnees$tps)^2
data.graph$sqrt.dim <- sqrt(donnees$dim)
data.graph$dim <- c()
data.graph$tps <- c()
```
Ensuite on trace les modèles de régression linéaires demandés.

```{r, echo = TRUE}
regressions <- list()

for (var in names(data.graph)) {
    if (var == "log.tps") {
        next
    }
    regressions[[var]] <- lm(log.tps ~ data.graph[[var]], data = data.graph)
}

par(mfrow = c(3, 2),mar = c(1, 8, 2, 1))
for (var in names(data.graph)) {
    if (var == "log.tps") {
        next
    }
    plot(regressions[[var]], main = "var", which = 1:5)
}
```
Nous pouvons observer que les variables avec des valeurs p élevées sont mean.dist, sd.deg, diameter. Cela suggère qu'elles ne sont pas statistiquement significatives dans le modèle et donc potenitellement non pertinente.

```{r}

regressions.group <- lm(log.tps ~ ., data = data.graph)
summary(regressions.group)
par(mfrow = c(3, 2),mar = c(4, 8, 2, 1))
plot(regressions.group, which = 1:6)
```
On observe 
### Mise en oeuvre de la selection de variables

On sélectionne les variables qui sont le plus pertinente au modèle de régression linéaire.
```{r, echo = TRUE}
regressions.aiced <- step(regressions.group)
plot(regressions.aiced)
summary(regressions.aiced)
```
```